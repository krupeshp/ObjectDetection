{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import cv2\n", "from imutils.video import FPS\n", "import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_yolo_preds(net, input_vid_path, output_vid_path, confidence_threshold, overlapping_threshold, write_output,\n", "                   show_display, labels):\n", "    # Get layer names that output predictions from YOLO\n", "    # List of colors to represent each class label with distinct color\n", "    np.random.seed(123)\n", "    colors = np.random.randint(0, 255, size=(len(labels), 3), dtype=\"uint8\")\n", "    ln = net.getLayerNames()\n", "    ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]\n", "    W = None\n", "    H = None\n", "    cap = cv2.VideoCapture(input_vid_path)\n", "    if (cap.isOpened() == False):\n", "        print(\"Error opening video stream or file\")\n", "        return\n", "    (success, frame) = cap.read()\n", "    # frame = imutils.resize(frame, width=640)\n", "    if write_output:\n", "        out = cv2.VideoWriter(output_vid_path,cv2.VideoWriter_fourcc(\n", "            *\"MJPG\"), cap.get(cv2.CAP_PROP_FPS), (frame.shape[1], frame.shape[0]), True)\n", "    fps = FPS().start()\n", "    while success:\n", "        # frame = imutils.resize(frame, width=640)\n", "        if W is None or H is None:\n", "            (H, W) = frame.shape[:2]\n\n", "        # Construct blob of frames by standardization, resizing, and swapping Red and Blue channels (RBG to RGB)\n", "        blob = cv2.dnn.blobFromImage(\n", "            frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n", "        net.setInput(blob)\n", "        layerOutputs = net.forward(ln)\n", "        boxes = []\n", "        confidences = []\n", "        classIDs = []\n", "        for output in layerOutputs:\n", "            for detection in output:\n", "                scores = detection[5:]\n", "                classID = np.argmax(scores)\n", "                confidence = scores[classID]\n", "                if confidence > confidence_threshold:\n", "                    # Scale the bboxes back to the original image size\n", "                    box = detection[0:4] * np.array([W, H, W, H])\n", "                    (centerX, centerY, width, height) = box.astype(\"int\")\n", "                    x = int(centerX - (width / 2))\n", "                    y = int(centerY - (height / 2))\n", "                    boxes.append([x, y, int(width), int(height)])\n", "                    confidences.append(float(confidence))\n", "                    classIDs.append(classID)\n\n", "        # Remove overlapping bounding boxes and boundig boxes\n", "        bboxes = cv2.dnn.NMSBoxes(\n", "            boxes, confidences, confidence_threshold, overlapping_threshold)\n", "        if len(bboxes) > 0:\n", "            for i in bboxes.flatten():\n", "                (x, y) = (boxes[i][0], boxes[i][1])\n", "                (w, h) = (boxes[i][2], boxes[i][3])\n", "                color = [int(c) for c in colors[classIDs[i]]]\n", "                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 1)\n", "                text = \"{}: {:.4f}\".format(labels[classIDs[i]], confidences[i])\n", "                cv2.putText(frame, text, (x, y - 5),\n", "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n", "        if show_display:\n", "            cv2.imshow(\"Predictions\", frame)\n", "            key = cv2.waitKey(1) & 0xFF\n", "            # if the `q` key was pressed, break the loop\n", "            if key == ord(\"q\"):\n", "                break\n", "        if write_output:\n", "            out.write(frame)\n", "        fps.update()\n", "        (success, frame) = cap.read()\n", "    fps.stop()\n", "    print(\"Elasped time: {:.2f}\".format(fps.elapsed()))\n", "    print(\"FPS: {:.2f}\".format(fps.fps()))\n", "    cap.release()\n", "    if write_output:\n", "        out.release()\n", "    # cv2.destroyAllWindows()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main(inputfile, cocofile, yolo_cfg, yolo_weight):\n", "    with open(cocofile, 'r') as f:\n", "        labels = f.read().split('\\n')\n", "    yolo_config_path = yolo_cfg\n", "    yolo_weights_path = yolo_weight\n", "    input_vid_path = './' + inputfile\n", "    show_display = True\n", "    write_output = True\n", "    output_vid_path = './.avi'\n", "    confidence_threshold = 0.5\n", "    overlapping_threshold = 0.3\n", "    net = cv2.dnn.readNetFromDarknet(yolo_config_path, yolo_weights_path)\n", "    get_yolo_preds(net, input_vid_path, output_vid_path, confidence_threshold, overlapping_threshold, write_output,\n", "                   show_display, labels)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["main(inputfile='v1.mp4', cocofile='coco.names', yolo_cfg='yolov3.cfg', yolo_weight='yolov3.weights')"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}